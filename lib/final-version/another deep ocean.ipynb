{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/yueyingteng/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os, pickle\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Convolution2D, Dense, Dropout, Flatten, MaxPooling2D\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import operator\n",
    "\n",
    "from subprocess import check_output\n",
    "# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "os.chdir('/Users/yueyingteng/Documents/2016.9/Big Data /kaggle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALB': 0,\n",
       " 'BET': 1,\n",
       " 'DOL': 2,\n",
       " 'LAG': 3,\n",
       " 'NoF': 4,\n",
       " 'OTHER': 5,\n",
       " 'SHARK': 6,\n",
       " 'YFT': 7}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ALB...\n",
      "Processing BET...\n",
      "Processing DOL...\n",
      "Processing LAG...\n",
      "Processing NoF...\n",
      "Processing OTHER...\n",
      "Processing SHARK...\n",
      "Processing YFT...\n"
     ]
    }
   ],
   "source": [
    "for d in os.listdir('./train'):\n",
    "    if d == '.DS_Store':\n",
    "        continue\n",
    "    print(\"Processing {}...\".format(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Unique number of labels:', 8)\n",
      "('Number of images:', 3777)\n",
      "('Length of label map:', 8)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "labels = []\n",
    "img_data = []\n",
    "\n",
    "label_map = dict(zip([i for i in os.listdir('./train') if not i=='.DS_Store'], range(8)))\n",
    "\n",
    "for d in os.listdir('./train'):\n",
    "#     print(\"Processing {}...\".format(d))\n",
    "    if d == '.DS_Store':\n",
    "        continue\n",
    "    f = [f for f in os.listdir(os.path.join('./train', d)) if not f =='.DS_Store']\n",
    "    for f in f:\n",
    "        labels.append(label_map[d])\n",
    "        im = load_img(os.path.join('./train', d, f))\n",
    "        im_data = img_to_array(im)\n",
    "        im_data.resize(64, 64, 3)\n",
    "        img_data.append(im_data)\n",
    "print(\"Unique number of labels:\", len(set(labels)))\n",
    "print(\"Number of images:\", len(img_data))\n",
    "print(\"Length of label map:\", len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32,3,3, border_mode='same', input_shape=(64,64,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32,3,3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(64,3,3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(8))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data converted...\n",
      "Model loaded...\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(img_data)\n",
    "y = np.array(labels)\n",
    "\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "print(\"Data converted...\")\n",
    "\n",
    "X /= 255.\n",
    "\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# y_train = np_utils.to_categorical(y_train)\n",
    "# y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "y = np_utils.to_categorical(y)\n",
    "\n",
    "model = cnn()\n",
    "print(\"Model loaded...\")\n",
    "# model.fit(X_train, y_train, nb_epoch=10, batch_size=64, verbose=2)\n",
    "model.fit(X, y, nb_epoch=10, batch_size=64, class_weight=None, verbose=2)\n",
    "\n",
    "# preds = model.predict(X_test)\n",
    "# print (\"Log loss on hold-out set:\", log_loss(y_test, preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of images', 1000)\n",
      "('Image size:', (64, 64, 3))\n"
     ]
    }
   ],
   "source": [
    "test_im_names = []\n",
    "test_imgs = []\n",
    "\n",
    "for fname in os.listdir('./test'):\n",
    "    if fname == '.DS_Store':\n",
    "        continue\n",
    "    test_im_names.append(fname)\n",
    "    im = load_img(os.path.join('./test', fname))\n",
    "    im_data = img_to_array(im)\n",
    "    im_data.resize(64, 64, 3)\n",
    "    test_imgs.append(im_data)\n",
    "    \n",
    "print(\"Number of images\", len(test_imgs))\n",
    "print(\"Image size:\", test_imgs[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test_final.astype('float32')\n",
    "X_test_final /= 255.\n",
    "\n",
    "final_preds = model.predict(X_test_final)\n",
    "\n",
    "prediction_df = pd.DataFrame(final_preds)\n",
    "prediction_df.columns = sorted(label_map.items(), key=operator.itemgetter(1))\n",
    "prediction_df['image'] = test_im_names\n",
    "prediction_df.to_csv('submission.csv', encoding='utf8', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
